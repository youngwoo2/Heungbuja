"""
ê²Œì„ í”Œë ˆì´ ë°ì´í„°ë¥¼ í™œìš©í•œ Fine-tuning ìŠ¤í¬ë¦½íŠ¸

ê²Œì„ ì¤‘ ìˆ˜ì§‘ëœ ì‹¤ì œ í”Œë ˆì´ ë°ì´í„°(game_data/)ë¥¼ ì‚¬ìš©í•˜ì—¬
ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ì„ ì¶”ê°€ë¡œ fine-tuningí•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    1. ê²Œì„ ë°ì´í„°ë¥¼ pose sequenceë¡œ ë³€í™˜
    2. ê¸°ì¡´ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì¶”ê°€ í•™ìŠµ

ì‚¬ìš© ì˜ˆì‹œ:
    python finetune_with_game_data.py --checkpoint ./checkpoints/brandnew_model_v1.pt --epochs 30
"""

from __future__ import annotations

import argparse
import json
import re
import sys
from collections import Counter, defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import cv2
import mediapipe as mp
import numpy as np
import torch
import torch.nn as nn
from PIL import Image, ImageOps

# train_gcn_cnn ëª¨ë“ˆ import
sys.path.insert(0, str(Path(__file__).parent.parent))
from brandnewTrain import train_gcn_cnn


# ê²Œì„ ë°ì´í„° íŒŒì¼ëª… íŒ¨í„´
# ì˜ˆ: 20251119_102637_258879_ì† ë°•ìˆ˜_1_frame00.jpg
GAME_DATA_PATTERN = re.compile(
    r"(?P<timestamp>\d{8}_\d{6}_\d+)_(?P<action_kr>[^_]+)_(?P<seq>\d+)_frame(?P<frame>\d+)\.(?P<ext>jpg|jpeg|png)$",
    re.IGNORECASE,
)

# í•œê¸€ ë™ì‘ëª… -> ì˜ì–´ ë§¤í•‘
ACTION_KR_TO_EN = {
    "ì† ë°•ìˆ˜": "CLAP",
    "íŒ” ì¹˜ê¸°": "ELBOW",  # ë˜ëŠ” ë‹¤ë¥¸ ë™ì‘
    "ë¹„ìƒêµ¬": "EXIT",
    "ì†ë»—ê¸°": "STRETCH",
    "íŒ”ë»—ê¸°": "STRETCH",
    "ê¸°ìš°ëš±": "TILT",
    "ê²¨ë“œë‘ì´": "UNDERARM",
    "ê°€ë§Œíˆ": "STAY",
}


@dataclass
class GameSequence:
    timestamp: str
    action_kr: str
    action_en: str
    seq_id: int
    frames: List[Tuple[int, Path]]  # (frame_id, path)


def collect_game_sequences(game_data_dir: Path) -> List[GameSequence]:
    """
    game_data ë””ë ‰í† ë¦¬ì—ì„œ í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³  ì‹œí€€ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
    """
    sequences_dict: Dict[str, GameSequence] = {}

    for image_path in sorted(game_data_dir.glob("*.jpg")):
        match = GAME_DATA_PATTERN.match(image_path.name)
        if not match:
            continue

        timestamp = match.group("timestamp")
        action_kr = match.group("action_kr")
        seq_id = int(match.group("seq"))
        frame_id = int(match.group("frame"))

        # í•œê¸€ ë™ì‘ëª…ì„ ì˜ì–´ë¡œ ë³€í™˜
        action_en = ACTION_KR_TO_EN.get(action_kr)
        if not action_en:
            print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ë™ì‘ëª…: {action_kr} (íŒŒì¼: {image_path.name})")
            continue

        # ì‹œí€€ìŠ¤ í‚¤ ìƒì„±
        seq_key = f"{timestamp}_{action_kr}_{seq_id}"

        if seq_key not in sequences_dict:
            sequences_dict[seq_key] = GameSequence(
                timestamp=timestamp,
                action_kr=action_kr,
                action_en=action_en,
                seq_id=seq_id,
                frames=[],
            )

        sequences_dict[seq_key].frames.append((frame_id, image_path))

    # í”„ë ˆì„ì„ í”„ë ˆì„ ID ìˆœìœ¼ë¡œ ì •ë ¬
    for seq in sequences_dict.values():
        seq.frames.sort(key=lambda x: x[0])

    return list(sequences_dict.values())


def extract_landmarks_from_image(
    pose: mp.solutions.pose.Pose,
    image_path: Path,
) -> Optional[np.ndarray]:
    """ì´ë¯¸ì§€ì—ì„œ MediaPipe í¬ì¦ˆ ëœë“œë§ˆí¬ ì¶”ì¶œ"""
    with Image.open(image_path) as pil_img:
        # EXIF íšŒì „ ë³´ì •
        pil_img = ImageOps.exif_transpose(pil_img)
        if pil_img is None:
            pil_img = Image.open(image_path)

        image_rgb = np.array(pil_img.convert("RGB"))
        image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)

    if image is None:
        return None

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)

    if not results.pose_landmarks:
        return None

    landmarks = np.array(
        [[lm.x, lm.y] for lm in results.pose_landmarks.landmark],
        dtype=np.float32,
    )
    return landmarks


def convert_game_data_to_sequences(
    game_data_dir: Path,
    output_dir: Path,
    frames_per_sample: int = 8,
    model_complexity: int = 1,
    min_detection_confidence: float = 0.5,
) -> List[Path]:
    """
    ê²Œì„ ë°ì´í„°ë¥¼ pose sequence (.npz)ë¡œ ë³€í™˜

    Returns:
        ì €ì¥ëœ .npz íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    print(f"\n{'='*70}")
    print(f"ğŸ® ê²Œì„ ë°ì´í„°ë¥¼ Pose Sequenceë¡œ ë³€í™˜ ì¤‘...")
    print(f"{'='*70}")
    print(f"ì…ë ¥: {game_data_dir}")
    print(f"ì¶œë ¥: {output_dir}")
    print(f"{'='*70}\n")

    sequences = collect_game_sequences(game_data_dir)

    if not sequences:
        print("âš ï¸  ê²Œì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    print(f"ì´ {len(sequences)}ê°œ ì‹œí€€ìŠ¤ ë°œê²¬\n")

    # ë™ì‘ë³„ í†µê³„
    action_counts = Counter(seq.action_en for seq in sequences)
    print("ë™ì‘ë³„ ì‹œí€€ìŠ¤ ìˆ˜:")
    for action, count in sorted(action_counts.items()):
        print(f"  {action:10s}: {count:3d}ê°œ")
    print()

    saved_paths: List[Path] = []
    mp_pose = mp.solutions.pose

    with mp_pose.Pose(
        static_image_mode=True,
        model_complexity=model_complexity,
        enable_segmentation=False,
        min_detection_confidence=min_detection_confidence,
    ) as pose:
        for seq in sequences:
            if len(seq.frames) != frames_per_sample:
                print(
                    f"âš ï¸  í”„ë ˆì„ ìˆ˜ ë¶ˆì¼ì¹˜: {seq.action_en} (seq {seq.seq_id}) "
                    f"- {len(seq.frames)}ê°œ (ê¸°ëŒ€: {frames_per_sample})"
                )
                continue

            # ê° í”„ë ˆì„ì—ì„œ ëœë“œë§ˆí¬ ì¶”ì¶œ
            frame_landmarks: List[np.ndarray] = []
            skip_sequence = False

            for frame_idx, image_path in seq.frames:
                landmarks = extract_landmarks_from_image(pose, image_path)
                if landmarks is None:
                    print(f"âš ï¸  í¬ì¦ˆ ì¶”ì¶œ ì‹¤íŒ¨: {image_path.name}")
                    skip_sequence = True
                    break
                frame_landmarks.append(landmarks)

            if skip_sequence:
                continue

            # ì‹œí€€ìŠ¤ ì €ì¥
            landmarks_array = np.stack(frame_landmarks, axis=0)

            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (GAME_DATA/ë™ì‘/)
            action_output_dir = output_dir / "GAME_DATA" / seq.action_en
            action_output_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ëª… ìƒì„±
            filename = f"{seq.action_en.lower()}_{seq.timestamp}_seq{seq.seq_id:03d}.npz"
            output_path = action_output_dir / filename

            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "person": "GAME_DATA",
                "action": seq.action_en,
                "sequence_id": seq.seq_id,
                "timestamp": seq.timestamp,
                "frames_per_sample": frames_per_sample,
                "landmark_count": landmarks_array.shape[1],
            }

            np.savez_compressed(
                output_path,
                landmarks=landmarks_array,
                metadata=json.dumps(metadata),
            )

            saved_paths.append(output_path)

            if len(saved_paths) % 10 == 0:
                print(f"  âœ“ {len(saved_paths)}ê°œ ì‹œí€€ìŠ¤ ë³€í™˜ ì™„ë£Œ...")

    print(f"\nâœ… ì´ {len(saved_paths)}ê°œ ì‹œí€€ìŠ¤ ë³€í™˜ ì™„ë£Œ")
    print(f"{'='*70}\n")

    return saved_paths


def load_checkpoint_for_finetuning(
    checkpoint_path: Path,
    device: torch.device,
) -> Tuple[nn.Module, Dict, argparse.Namespace]:
    """
    ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ë° fine-tuning ì¤€ë¹„

    Returns:
        (model, action_to_label, original_args)
    """
    print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: {checkpoint_path}")

    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)

    # ì €ì¥ëœ args ë³µì›
    original_args = checkpoint["args"]

    # argsê°€ dictì¸ ê²½ìš° argparse.Namespaceë¡œ ë³€í™˜
    if isinstance(original_args, dict):
        from argparse import Namespace
        original_args = Namespace(**original_args)

    # action_to_label ë˜ëŠ” class_mapping í‚¤ í™•ì¸
    if "action_to_label" in checkpoint:
        action_to_label = checkpoint["action_to_label"]
    elif "class_mapping" in checkpoint:
        action_to_label = checkpoint["class_mapping"]
    else:
        raise KeyError(f"ì²´í¬í¬ì¸íŠ¸ì— 'action_to_label' ë˜ëŠ” 'class_mapping' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(checkpoint.keys())}")

    # ëª¨ë¸ ì¬ìƒì„±
    input_dim = 2
    adjacency = train_gcn_cnn.build_adjacency(train_gcn_cnn.USED_LANDMARK_INDICES)

    model = train_gcn_cnn.GCNTemporalModel(
        input_dim=input_dim,
        num_classes=len(action_to_label),
        adjacency=adjacency,
        gcn_hidden_dims=original_args.gcn_hidden_dims,
        temporal_channels=original_args.temporal_channels,
        dropout=original_args.dropout,
    )

    # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.load_state_dict(checkpoint["model_state_dict"])
    model.to(device)

    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (í´ë˜ìŠ¤ ìˆ˜: {len(action_to_label)})")
    print(f"   ë™ì‘ ë ˆì´ë¸”: {sorted(action_to_label.keys())}")

    return model, action_to_label, original_args


def finetune_with_game_data(
    checkpoint_path: Path,
    game_pose_dir: Path,
    original_pose_dir: Optional[Path],
    epochs: int,
    learning_rate: float,
    batch_size: int,
    save_dir: Path,
    save_name: str,
    val_split: float,
    seed: int,
    device: str,
    use_class_weights: bool,
) -> None:
    """
    ê²Œì„ ë°ì´í„°ë¡œ ëª¨ë¸ Fine-tuning
    """
    train_gcn_cnn.set_seed(seed)
    device = train_gcn_cnn.auto_device(device)

    # 1. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    model, action_to_label, original_args = load_checkpoint_for_finetuning(
        checkpoint_path, device
    )
    label_to_action = {label: action for action, label in action_to_label.items()}

    # 2. ìƒ˜í”Œ ìˆ˜ì§‘
    print(f"\n{'='*70}")
    print("ğŸ“Š í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘")
    print(f"{'='*70}")

    samples = []

    # ê²Œì„ ë°ì´í„° ìˆ˜ì§‘
    game_samples = train_gcn_cnn.collect_samples(
        data_dir=game_pose_dir,
        action_to_label=action_to_label,
        frames_per_sample=original_args.frames_per_sample,
        persons=None,
        actions=list(action_to_label.keys()),
    )
    print(f"ğŸ® ê²Œì„ ë°ì´í„°: {len(game_samples)}ê°œ")

    samples.extend(game_samples)

    # ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ì¶”ê°€ (ì„ íƒì )
    if original_pose_dir and original_pose_dir.exists():
        original_samples = train_gcn_cnn.collect_samples(
            data_dir=original_pose_dir,
            action_to_label=action_to_label,
            frames_per_sample=original_args.frames_per_sample,
            persons=None,
            actions=list(action_to_label.keys()),
        )
        print(f"ğŸ“š ê¸°ì¡´ ë°ì´í„°: {len(original_samples)}ê°œ")
        samples.extend(original_samples)

    print(f"ğŸ“¦ ì´ ìƒ˜í”Œ: {len(samples)}ê°œ")

    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    class_counts = Counter(sample.label for sample in samples)
    print("\ní´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
    for label in sorted(class_counts.keys()):
        action = label_to_action[label]
        count = class_counts[label]
        print(f"  {action:10s}: {count:4d}ê°œ")

    # 3. Train/Val split
    train_samples, val_samples = train_gcn_cnn.split_samples(samples, val_split, seed)

    print(f"\nâ–¶ í•™ìŠµ ìƒ˜í”Œ: {len(train_samples)}ê°œ, ê²€ì¦ ìƒ˜í”Œ: {len(val_samples)}ê°œ")
    train_gcn_cnn.print_split_summary("TRAIN", train_samples)
    if val_samples:
        train_gcn_cnn.print_split_summary("VAL", val_samples)

    # 4. DataLoader ìƒì„±
    dataset_args = dict(frames_per_sample=original_args.frames_per_sample)
    train_dataset = train_gcn_cnn.PoseSequenceDataset(train_samples, **dataset_args)
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=True,
    )

    val_loader = None
    if val_samples:
        val_dataset = train_gcn_cnn.PoseSequenceDataset(val_samples, **dataset_args)
        val_loader = torch.utils.data.DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=True,
        )

    # 5. Optimizer & Loss
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=learning_rate,
        weight_decay=original_args.weight_decay,
    )
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© (ì„ íƒì )
    if use_class_weights:
        total_samples = len(samples)
        num_classes = len(action_to_label)
        class_weights = torch.zeros(num_classes)

        for label, count in class_counts.items():
            class_weights[label] = total_samples / (num_classes * count)

        class_weights = class_weights / class_weights.sum() * num_classes
        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))

        print("\nâš–ï¸  í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©:")
        for label in sorted(class_counts.keys()):
            action = label_to_action[label]
            weight = class_weights[label].item()
            print(f"  {action:10s}: {weight:.3f}")
    else:
        criterion = nn.CrossEntropyLoss()

    # 6. Fine-tuning ì‹œì‘
    print(f"\n{'='*70}")
    print("ğŸ”¥ Fine-tuning ì‹œì‘")
    print(f"{'='*70}\n")

    import math
    best_val_acc = -math.inf
    best_epoch = -1
    checkpoint_path_out = save_dir / save_name

    for epoch in range(1, epochs + 1):
        train_result = train_gcn_cnn.train_one_epoch(
            model,
            train_loader,
            criterion,
            optimizer,
            device,
            grad_clip=original_args.grad_clip,
        )

        scheduler.step()

        if val_loader:
            val_result = train_gcn_cnn.evaluate(
                model, val_loader, criterion, device, label_to_action
            )
            val_loss = val_result.loss
            val_acc = val_result.accuracy

            print(
                f"[Epoch {epoch:3d}/{epochs}] "
                f"Train Loss={train_result.loss:.4f} Acc={train_result.accuracy:.2%} | "
                f"Val Loss={val_loss:.4f} Acc={val_acc:.2%}"
            )

            if val_result.per_action:
                for action, (correct, total) in sorted(val_result.per_action.items()):
                    acc = correct / total if total > 0 else 0
                    print(f"  {action:10s}: {correct:3d}/{total:3d} ({acc:.1%})")

            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_epoch = epoch

                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                train_gcn_cnn.save_checkpoint(
                    checkpoint_path_out,
                    model,
                    optimizer,
                    epoch,
                    best_val_acc,
                    original_args,
                    action_to_label,
                )
                print(f"  âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path_out}")
        else:
            print(
                f"[Epoch {epoch:3d}/{epochs}] "
                f"Train Loss={train_result.loss:.4f} Acc={train_result.accuracy:.2%}"
            )

    print(f"\n{'='*70}")
    print(f"ğŸ‰ Fine-tuning ì™„ë£Œ!")
    print(f"   ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.2%} (Epoch {best_epoch})")
    print(f"   ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {checkpoint_path_out}")
    print(f"{'='*70}\n")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="ê²Œì„ ë°ì´í„°ë¡œ ëª¨ë¸ Fine-tuning")

    parser.add_argument(
        "--checkpoint",
        type=str,
        required=True,
        help="ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (.pt)",
    )
    parser.add_argument(
        "--game_data_dir",
        type=str,
        default="./app/brandnewTrain/game_data",
        help="ê²Œì„ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ./app/brandnewTrain/game_data)",
    )
    parser.add_argument(
        "--original_pose_dir",
        type=str,
        default=None,
        help="ê¸°ì¡´ pose_sequences ë””ë ‰í† ë¦¬ (ì¶”ê°€ í•™ìŠµ ì‹œ)",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=30,
        help="Fine-tuning epoch ìˆ˜ (ê¸°ë³¸: 30)",
    )
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=1e-4,
        help="Learning rate (ê¸°ë³¸: 1e-4, ì›ë˜ í•™ìŠµë³´ë‹¤ ë‚®ê²Œ ì„¤ì •)",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=32,
        help="Batch size (ê¸°ë³¸: 32)",
    )
    parser.add_argument(
        "--save_dir",
        type=str,
        default="./app/brandnewTrain/checkpoints",
        help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬",
    )
    parser.add_argument(
        "--save_name",
        type=str,
        default="brandnew_finetuned_v1.pt",
        help="ì €ì¥í•  ëª¨ë¸ íŒŒì¼ëª…",
    )
    parser.add_argument(
        "--val_split",
        type=float,
        default=0.2,
        help="Validation split ë¹„ìœ¨ (ê¸°ë³¸: 0.2)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="í•™ìŠµ ë””ë°”ì´ìŠ¤ (auto, cpu, cuda)",
    )
    parser.add_argument(
        "--use_class_weights",
        action="store_true",
        help="í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© (ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬)",
    )
    parser.add_argument(
        "--skip_conversion",
        action="store_true",
        help="ê²Œì„ ë°ì´í„° ë³€í™˜ ìŠ¤í‚µ (ì´ë¯¸ ë³€í™˜ëœ ê²½ìš°)",
    )

    return parser.parse_args()


def main() -> None:
    args = parse_args()

    checkpoint_path = Path(args.checkpoint)
    if not checkpoint_path.exists():
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        sys.exit(1)

    game_data_dir = Path(args.game_data_dir)
    if not game_data_dir.exists():
        print(f"âŒ ê²Œì„ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {game_data_dir}")
        sys.exit(1)

    # ê²Œì„ ë°ì´í„° ë³€í™˜ (pose sequenceë¡œ)
    game_pose_dir = Path("./app/brandnewTrain/game_pose_sequences")

    if not args.skip_conversion:
        convert_game_data_to_sequences(
            game_data_dir=game_data_dir,
            output_dir=game_pose_dir,
            frames_per_sample=8,
            model_complexity=1,
            min_detection_confidence=0.5,
        )
    else:
        print("â­ï¸  ê²Œì„ ë°ì´í„° ë³€í™˜ ìŠ¤í‚µ")

    # ê¸°ì¡´ pose_sequences ê²½ë¡œ
    original_pose_dir = None
    if args.original_pose_dir:
        original_pose_dir = Path(args.original_pose_dir)

    # Fine-tuning ì‹¤í–‰
    save_dir = Path(args.save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)

    finetune_with_game_data(
        checkpoint_path=checkpoint_path,
        game_pose_dir=game_pose_dir,
        original_pose_dir=original_pose_dir,
        epochs=args.epochs,
        learning_rate=args.learning_rate,
        batch_size=args.batch_size,
        save_dir=save_dir,
        save_name=args.save_name,
        val_split=args.val_split,
        seed=args.seed,
        device=args.device,
        use_class_weights=args.use_class_weights,
    )


if __name__ == "__main__":
    main()
