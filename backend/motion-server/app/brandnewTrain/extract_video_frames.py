"""
ë™ì˜ìƒì—ì„œ ë™ì‘ ë°ì´í„° ìë™ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ (ë™ì‘ë³„ ë§ì¶¤ ì£¼ê¸°)

100bpm ê¸°ì¤€ìœ¼ë¡œ ë™ì‘ë³„ ë¦¬ë“¬ì— ë§ì¶° í”„ë ˆì„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤:
- CLAP: 1ë°•ìë‹¹ 1ë™ì‘ (0.6ì´ˆ)
- ë‚˜ë¨¸ì§€: 2ë°•ìë‹¹ 1ë™ì‘ (1.2ì´ˆ)

ì‚¬ìš©ë²•:
    # í´ë” ì¼ê´„ ì²˜ë¦¬ (ê¶Œì¥)
    python extract_video_frames.py --video_dir ./origin_data --output_dir ./extracted_data

    # íŠ¹ì • ë™ì˜ìƒë§Œ ì²˜ë¦¬
    python extract_video_frames.py --video_dir ./origin_data --actions CLAP STRETCH

ì¶œë ¥:
    extracted_data/
    â”œâ”€â”€ PERSON1/
    â”‚   â”œâ”€â”€ CLAP/
    â”‚   â”‚   â”œâ”€â”€ clap_seq001_frame1.jpg
    â”‚   â”‚   â”œâ”€â”€ clap_seq001_frame2.jpg
    â”‚   â”‚   â”œâ”€â”€ ...
    â”‚   â”‚   â””â”€â”€ clap_seq001_frame8.jpg
    â”‚   â””â”€â”€ STRETCH/
    â”‚       â””â”€â”€ ...
    â””â”€â”€ PERSON2/
        â””â”€â”€ ...
"""

from __future__ import annotations

import argparse
import re
from pathlib import Path
from typing import Dict, List, Optional

import cv2
import numpy as np


# ë™ì‘ë³„ ì„¤ì •
ACTION_CONFIG = {
    "CLAP": {
        "beats_per_action": 1,  # 1ë°•ìë‹¹ 1ë™ì‘
        "seconds_per_action": 0.6,  # 100bpmì—ì„œ 1ë°•ì = 0.6ì´ˆ
    },
    "ELBOW": {
        "beats_per_action": 2,
        "seconds_per_action": 1.2,
    },
    "STRETCH": {
        "beats_per_action": 2,
        "seconds_per_action": 1.2,
    },
    "TILT": {
        "beats_per_action": 2,
        "seconds_per_action": 1.2,
    },
    "EXIT": {
        "beats_per_action": 2,
        "seconds_per_action": 1.2,
    },
    "UNDERARM": {
        "beats_per_action": 2,
        "seconds_per_action": 1.2,
    },
    "STAY": {
        "beats_per_action": 2,
        "seconds_per_action": 1.2,
    },
}

SUPPORTED_ACTIONS = list(ACTION_CONFIG.keys())
VIDEO_EXTENSIONS = [".mp4", ".avi", ".mov", ".mkv", ".MP4", ".AVI", ".MOV", ".MKV"]

# íŒŒì¼ëª…ì—ì„œ ì¸ë¬¼ ì´ë¦„ ì¶”ì¶œ íŒ¨í„´
PERSON_PATTERN = re.compile(
    r"(?P<person>[A-Z]{3}|[ê°€-í£]+)_(?P<action>[A-Z]+)",
    re.IGNORECASE,
)


def extract_person_and_action(filename: str) -> tuple[Optional[str], Optional[str]]:
    """
    íŒŒì¼ëª…ì—ì„œ ì¸ë¬¼ê³¼ ë™ì‘ ì¶”ì¶œ

    ì˜ˆì‹œ:
        KSM_CLAP.mp4 â†’ ("KSM", "CLAP")
        ìˆ˜ì—°_ë°•ìˆ˜.mp4 â†’ ("ìˆ˜ì—°", None)  # í•œê¸€ ë™ì‘ëª…ì€ ë§¤í•‘ í•„ìš”
        CLAP.mp4 â†’ (None, "CLAP")
    """
    match = PERSON_PATTERN.search(filename)
    if match:
        person = match.group("person").upper()
        action_raw = match.group("action").upper()

        # í•œê¸€ ë™ì‘ëª… ë§¤í•‘
        korean_action_map = {
            "ë°•ìˆ˜": "CLAP",
            "íŒ”ê¿ˆì¹˜": "ELBOW",
            "ìŠ¤íŠ¸ë ˆì¹­": "STRETCH",
            "ìŠ¤íŠ¸ë ˆì¹˜": "STRETCH",
            "ê¸°ìš¸ì´ê¸°": "TILT",
            "ë¹„ìƒêµ¬": "EXIT",
            "ê²¨ë“œë‘ì´": "UNDERARM",
            "ëŒ€ê¸°": "STAY",
        }

        # ì˜ì–´ ë™ì‘ëª…ì´ë©´ ê·¸ëŒ€ë¡œ, í•œê¸€ì´ë©´ ë§¤í•‘
        if action_raw in SUPPORTED_ACTIONS:
            action = action_raw
        else:
            # íŒŒì¼ëª… ì „ì²´ì—ì„œ í•œê¸€ ë™ì‘ëª… ì°¾ê¸°
            for korean, english in korean_action_map.items():
                if korean in filename:
                    action = english
                    break
            else:
                action = None

        return person, action

    # íŒ¨í„´ì´ ë§¤ì¹­ ì•ˆ ë˜ë©´ íŒŒì¼ëª…ì—ì„œ ë™ì‘ëª…ë§Œì´ë¼ë„ ì°¾ê¸°
    filename_upper = filename.upper()
    for action in SUPPORTED_ACTIONS:
        if action in filename_upper:
            return None, action

    return None, None


def get_video_rotation(video_path: Path) -> int:
    """
    ë™ì˜ìƒì˜ íšŒì „ ë©”íƒ€ë°ì´í„° í™•ì¸

    Returns:
        0, 90, 180, 270 (ì‹œê³„ë°©í–¥ íšŒì „ ê°ë„)
    """
    try:
        import subprocess
        import json

        # ffprobeë¡œ ë©”íƒ€ë°ì´í„° ì½ê¸°
        result = subprocess.run(
            [
                'ffprobe',
                '-v', 'quiet',
                '-print_format', 'json',
                '-show_streams',
                str(video_path)
            ],
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode == 0:
            data = json.loads(result.stdout)
            for stream in data.get('streams', []):
                if stream.get('codec_type') == 'video':
                    # rotation íƒœê·¸ í™•ì¸
                    rotation = stream.get('tags', {}).get('rotate', '0')
                    return int(rotation)
    except Exception:
        # ffprobeê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•˜ë©´ 0 ë°˜í™˜
        pass

    return 0


def rotate_frame(frame: np.ndarray, rotation: int) -> np.ndarray:
    """
    í”„ë ˆì„ì„ íšŒì „ ê°ë„ì— ë§ì¶° ë³´ì •

    Args:
        frame: ì›ë³¸ í”„ë ˆì„
        rotation: ì‹œê³„ë°©í–¥ íšŒì „ ê°ë„ (0, 90, 180, 270)

    Returns:
        ë³´ì •ëœ í”„ë ˆì„
    """
    if rotation == 90:
        # ì‹œê³„ë°©í–¥ 90ë„ íšŒì „ â†’ ë°˜ì‹œê³„ë°©í–¥ 90ë„ë¡œ ë³´ì •
        return cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
    elif rotation == 180:
        return cv2.rotate(frame, cv2.ROTATE_180)
    elif rotation == 270:
        # ì‹œê³„ë°©í–¥ 270ë„ = ë°˜ì‹œê³„ë°©í–¥ 90ë„ â†’ ì‹œê³„ë°©í–¥ 90ë„ë¡œ ë³´ì •
        return cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
    else:
        return frame


def extract_frames_from_video(
    video_path: Path,
    action_name: str,
    person_name: Optional[str],
    output_dir: Path,
    frames_per_sample: int = 8,
    start_offset: float = 0.0,
    end_offset: float = 0.0,
) -> int:
    """
    ë™ì˜ìƒì—ì„œ ë™ì‘ë³„ ë§ì¶¤ ì£¼ê¸°ë¡œ í”„ë ˆì„ ì¶”ì¶œ

    Returns:
        ì¶”ì¶œëœ ì‹œí€€ìŠ¤ ê°œìˆ˜
    """
    if action_name not in ACTION_CONFIG:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë™ì‘: {action_name}")

    config = ACTION_CONFIG[action_name]
    seconds_per_action = config["seconds_per_action"]

    # ë™ì˜ìƒ íšŒì „ ë©”íƒ€ë°ì´í„° í™•ì¸
    rotation = get_video_rotation(video_path)

    # ë™ì˜ìƒ ì—´ê¸°
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"ë™ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps

    print(f"\n{'='*70}")
    print(f"ğŸ“¹ {video_path.name}")
    print(f"{'='*70}")
    print(f"ì¸ë¬¼: {person_name or 'Unknown'}")
    print(f"ë™ì‘: {action_name}")
    print(f"ë™ì˜ìƒ ì •ë³´: {fps:.2f}fps, {duration:.2f}ì´ˆ, {total_frames} í”„ë ˆì„")
    print(f"ë™ì‘ ì£¼ê¸°: {seconds_per_action}ì´ˆ ({config['beats_per_action']}ë°•ì)")
    if rotation != 0:
        print(f"âš ï¸  íšŒì „ ë³´ì •: {rotation}ë„ (ìë™ ë³´ì • ì ìš©)")

    # ì˜¤í”„ì…‹ ì ìš©
    start_frame = int(fps * start_offset)
    end_frame = total_frames - int(fps * end_offset)
    usable_frames = end_frame - start_frame
    usable_duration = usable_frames / fps

    if start_offset > 0 or end_offset > 0:
        print(f"ì˜¤í”„ì…‹: ì‹œì‘ {start_offset}ì´ˆ, ë {end_offset}ì´ˆ ê±´ë„ˆë›°ê¸°")
        print(f"ì‚¬ìš© êµ¬ê°„: {usable_duration:.2f}ì´ˆ")

    # 1ì‚¬ì´í´ = 1ë™ì‘
    frames_per_cycle = int(fps * seconds_per_action)
    max_cycles = int(usable_duration / seconds_per_action)

    print(f"ì˜ˆìƒ ì‹œí€€ìŠ¤: {max_cycles}ê°œ")
    print(f"{'='*70}")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)

    # í”„ë ˆì„ ì¶”ì¶œ
    saved_sequences = 0

    for cycle_idx in range(max_cycles):
        cycle_start_frame = start_frame + cycle_idx * frames_per_cycle
        cycle_end_frame = min(cycle_start_frame + frames_per_cycle, end_frame)

        sample_frames = []

        # ì´ ì‚¬ì´í´ì—ì„œ ê· ë“±í•˜ê²Œ frames_per_sampleê°œ ì¶”ì¶œ
        for i in range(frames_per_sample):
            # ì„ í˜• ë³´ê°„ìœ¼ë¡œ ê· ë“± ìƒ˜í”Œë§
            if frames_per_sample > 1:
                progress = i / (frames_per_sample - 1)
            else:
                progress = 0.0

            target_frame = int(cycle_start_frame + progress * (cycle_end_frame - cycle_start_frame - 1))
            target_frame = min(target_frame, end_frame - 1)

            cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            ret, frame = cap.read()

            if not ret:
                print(f"âš ï¸  í”„ë ˆì„ {target_frame} ì½ê¸° ì‹¤íŒ¨")
                break

            # íšŒì „ ë³´ì • ì ìš©
            if rotation != 0:
                frame = rotate_frame(frame, rotation)

            sample_frames.append(frame)

        # frames_per_sampleê°œ ëª¨ë‘ ì¶”ì¶œí–ˆìœ¼ë©´ ì €ì¥
        if len(sample_frames) == frames_per_sample:
            seq_number = cycle_idx + 1

            for frame_num, frame in enumerate(sample_frames, 1):
                filename = output_dir / f"{action_name.lower()}_seq{seq_number:03d}_frame{frame_num}.jpg"
                cv2.imwrite(str(filename), frame)

            saved_sequences += 1

            if saved_sequences % 10 == 0:
                print(f"  âœ“ {saved_sequences}ê°œ ì‹œí€€ìŠ¤ ì¶”ì¶œ ì¤‘...")

    cap.release()

    print(f"âœ… ì™„ë£Œ: {saved_sequences}ê°œ ì‹œí€€ìŠ¤ ì¶”ì¶œ")
    return saved_sequences


def process_video_directory(
    video_dir: Path,
    output_base_dir: Path,
    frames_per_sample: int = 8,
    start_offset: float = 0.0,
    end_offset: float = 0.0,
    action_filter: Optional[List[str]] = None,
) -> Dict[str, int]:
    """
    í´ë” êµ¬ì¡°ë¥¼ ìˆœíšŒí•˜ë©° ëª¨ë“  ë™ì˜ìƒ ì²˜ë¦¬

    ì…ë ¥ êµ¬ì¡°:
        origin_data/
        â”œâ”€â”€ CLAP/
        â”‚   â”œâ”€â”€ KSM_CLAP.mp4
        â”‚   â””â”€â”€ ìˆ˜ì—°_ë°•ìˆ˜.mp4
        â””â”€â”€ STRETCH/
            â””â”€â”€ ...

    ì¶œë ¥ êµ¬ì¡°:
        extracted_data/
        â”œâ”€â”€ KSM/
        â”‚   â”œâ”€â”€ CLAP/
        â”‚   â”‚   â””â”€â”€ clap_seq001_frame1~8.jpg
        â”‚   â””â”€â”€ STRETCH/
        â”‚       â””â”€â”€ ...
        â””â”€â”€ ìˆ˜ì—°/
            â””â”€â”€ ...

    Returns:
        ë™ì‘ë³„ ì¶”ì¶œëœ ì‹œí€€ìŠ¤ ê°œìˆ˜
    """
    if not video_dir.exists():
        raise FileNotFoundError(f"ë™ì˜ìƒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_dir}")

    action_filter_set = set(action_filter) if action_filter else None

    print(f"\n{'='*70}")
    print(f"ğŸ“ í´ë” ì¼ê´„ ì²˜ë¦¬ ì‹œì‘")
    print(f"{'='*70}")
    print(f"ì…ë ¥ í´ë”: {video_dir}")
    print(f"ì¶œë ¥ í´ë”: {output_base_dir}")
    if action_filter_set:
        print(f"í•„í„°: {', '.join(action_filter_set)}")
    print(f"{'='*70}")

    # ë™ì‘ë³„ í´ë” ìˆœíšŒ
    stats = {}
    total_videos = 0
    total_sequences = 0

    for action_dir in sorted(video_dir.iterdir()):
        if not action_dir.is_dir():
            continue

        action_name = action_dir.name.upper()

        # ë™ì‘ í•„í„° ì ìš©
        if action_filter_set and action_name not in action_filter_set:
            continue

        if action_name not in SUPPORTED_ACTIONS:
            print(f"âš ï¸  ì§€ì›ë˜ì§€ ì•ŠëŠ” ë™ì‘ í´ë” ê±´ë„ˆëœ€: {action_name}")
            continue

        # í•´ë‹¹ ë™ì‘ í´ë”ì˜ ë™ì˜ìƒ íŒŒì¼ ì°¾ê¸°
        video_files = []
        for ext in VIDEO_EXTENSIONS:
            video_files.extend(action_dir.glob(f"*{ext}"))

        if not video_files:
            print(f"âš ï¸  {action_name} í´ë”ì— ë™ì˜ìƒ ì—†ìŒ")
            continue

        action_sequences = 0

        for video_file in sorted(video_files):
            person_name, detected_action = extract_person_and_action(video_file.stem)

            # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œí•œ ë™ì‘ê³¼ í´ë”ëª… ë¹„êµ
            if detected_action and detected_action != action_name:
                print(f"âš ï¸  ë™ì‘ ë¶ˆì¼ì¹˜: {video_file.name} (í´ë”: {action_name}, íŒŒì¼: {detected_action})")
                continue

            # ì¸ë¬¼ëª…ì´ ì—†ìœ¼ë©´ íŒŒì¼ëª… ì‚¬ìš©
            if not person_name:
                person_name = video_file.stem.split('_')[0] if '_' in video_file.stem else "UNKNOWN"

            # ì¶œë ¥ ê²½ë¡œ: output_base_dir/PERSON/ACTION/
            output_dir = output_base_dir / person_name / action_name

            try:
                sequences = extract_frames_from_video(
                    video_path=video_file,
                    action_name=action_name,
                    person_name=person_name,
                    output_dir=output_dir,
                    frames_per_sample=frames_per_sample,
                    start_offset=start_offset,
                    end_offset=end_offset,
                )

                action_sequences += sequences
                total_videos += 1

            except Exception as e:
                print(f"âŒ {video_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\n")
                continue

        stats[action_name] = action_sequences
        total_sequences += action_sequences

    # ìš”ì•½
    print(f"\n{'='*70}")
    print(f"ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"{'='*70}")
    print(f"ì²˜ë¦¬ëœ ë™ì˜ìƒ: {total_videos}ê°œ")
    print(f"ì¶”ì¶œëœ ì‹œí€€ìŠ¤: {total_sequences}ê°œ")
    print(f"\në™ì‘ë³„ í†µê³„:")
    for action, count in sorted(stats.items()):
        print(f"  - {action}: {count}ê°œ ì‹œí€€ìŠ¤")
    print(f"\nì¶œë ¥ í´ë”: {output_base_dir}")
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"1. pose_sequence_extractor.pyë¡œ ëœë“œë§ˆí¬ ì¶”ì¶œ:")
    print(f"   python pose_sequence_extractor.py --data_dir {output_base_dir} --output_dir ./pose_sequences")
    print(f"\n2. ëª¨ë¸ í•™ìŠµ:")
    print(f"   python train_gcn_cnn.py --data_dir ./pose_sequences --epochs 50")
    print(f"{'='*70}\n")

    return stats


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="100bpm ë™ì‘ ë™ì˜ìƒì—ì„œ ë™ì‘ë³„ ë§ì¶¤ ì£¼ê¸°ë¡œ í”„ë ˆì„ ì¶”ì¶œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  # ì „ì²´ í´ë” ì²˜ë¦¬
  python extract_video_frames.py --video_dir ./origin_data --output_dir ./extracted_data

  # íŠ¹ì • ë™ì‘ë§Œ ì²˜ë¦¬
  python extract_video_frames.py --video_dir ./origin_data --actions CLAP STRETCH

  # ì‹œì‘ 1ì´ˆ ê±´ë„ˆë›°ê¸° (ì¹´ìš´íŠ¸ë‹¤ìš´ ë“±)
  python extract_video_frames.py --video_dir ./origin_data --start 1.0

  # í”„ë ˆì„ ìˆ˜ ë³€ê²½ (ê¸°ë³¸: 8)
  python extract_video_frames.py --video_dir ./origin_data --frames 16

ë™ì‘ë³„ ì£¼ê¸°:
  - CLAP: 0.6ì´ˆ (1ë°•ì)
  - ELBOW, STRETCH, TILT, EXIT, UNDERARM, STAY: 1.2ì´ˆ (2ë°•ì)
        """,
    )

    parser.add_argument(
        "--video_dir",
        type=str,
        required=True,
        help="ë™ì˜ìƒ í´ë” ê²½ë¡œ (origin_data/)",
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="extracted_data",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: extracted_data)",
    )
    parser.add_argument(
        "--frames",
        type=int,
        default=8,
        help="ê° ì‹œí€€ìŠ¤ë‹¹ í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸: 8)",
    )
    parser.add_argument(
        "--start",
        type=float,
        default=0.0,
        help="ë™ì˜ìƒ ì‹œì‘ ë¶€ë¶„ ê±´ë„ˆë›°ê¸° (ì´ˆ, ê¸°ë³¸: 0)",
    )
    parser.add_argument(
        "--end",
        type=float,
        default=0.0,
        help="ë™ì˜ìƒ ë ë¶€ë¶„ ê±´ë„ˆë›°ê¸° (ì´ˆ, ê¸°ë³¸: 0)",
    )
    parser.add_argument(
        "--actions",
        nargs="*",
        default=None,
        help=f"íŠ¹ì • ë™ì‘ë§Œ ì²˜ë¦¬ (ì˜ˆ: CLAP STRETCH). ê¸°ë³¸: ì „ì²´ ({', '.join(SUPPORTED_ACTIONS)})",
    )

    return parser.parse_args()


def main() -> None:
    args = parse_args()

    video_dir = Path(args.video_dir)
    output_dir = Path(args.output_dir)

    action_filter = [a.upper() for a in args.actions] if args.actions else None

    process_video_directory(
        video_dir=video_dir,
        output_base_dir=output_dir,
        frames_per_sample=args.frames,
        start_offset=args.start,
        end_offset=args.end,
        action_filter=action_filter,
    )


if __name__ == "__main__":
    main()
