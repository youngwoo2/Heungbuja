"""
í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ë¬¸ì œ:
- CLAP: ~100ê°œ
- ë‚˜ë¨¸ì§€: ~50ê°œì”©
- CLAPì´ 2ë°° ë§ì•„ì„œ ëª¨ë¸ì´ CLAPìœ¼ë¡œë§Œ ì˜ˆì¸¡

í•´ê²°:
- í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ìë™ ê³„ì‚°í•˜ì—¬ ê· í˜• ë§ì¶¤
- CLAPì˜ ì†ì‹¤ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶”ê³  ë‚˜ë¨¸ì§€ë¥¼ ë†’ì„
"""

import sys
import subprocess
from pathlib import Path
from collections import Counter

# ë°ì´í„° ë¶„í¬ í™•ì¸
def check_class_distribution():
    """í´ë˜ìŠ¤ë³„ ë°ì´í„° ê°œìˆ˜ í™•ì¸"""
    import glob

    data_dir = Path("app/brandnewTrain/pose_sequences")
    if not data_dir.exists():
        print(f"âŒ ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        return None

    class_counts = Counter()

    # ëª¨ë“  npz íŒŒì¼ ìˆ˜ì§‘
    for person_dir in data_dir.iterdir():
        if not person_dir.is_dir():
            continue

        for action_dir in person_dir.iterdir():
            if not action_dir.is_dir():
                continue

            action = action_dir.name
            npz_files = list(action_dir.glob("*.npz"))
            class_counts[action] += len(npz_files)

    return class_counts


print("\n" + "=" * 80)
print("ğŸ” í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸")
print("=" * 80)

class_counts = check_class_distribution()
if class_counts:
    total = sum(class_counts.values())
    print(f"\nì´ ìƒ˜í”Œ ìˆ˜: {total}ê°œ\n")

    for action in sorted(class_counts.keys()):
        count = class_counts[action]
        percentage = count / total * 100
        bar = "â–ˆ" * int(percentage / 2)
        print(f"  {action:10s}: {count:4d}ê°œ ({percentage:5.1f}%) {bar}")

    # ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°
    max_count = max(class_counts.values())
    min_count = min(class_counts.values())
    imbalance_ratio = max_count / min_count

    print(f"\nâš ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}ë°°")

    if imbalance_ratio > 1.5:
        print("   â†’ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© í•„ìš”!")

    print("=" * 80 + "\n")

# train_gcn_cnn.pyë¥¼ importí•´ì„œ ìˆ˜ì •ëœ ë²„ì „ìœ¼ë¡œ í•™ìŠµ
print("ğŸ“š í•™ìŠµ ì‹œì‘ (í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ìë™ ì ìš©)")
print("=" * 80 + "\n")

# í•™ìŠµ ì‹¤í–‰
cmd = [
    sys.executable,
    "-c",
    """
import sys
sys.path.insert(0, '.')

# train_gcn_cnn ì„í¬íŠ¸
from app.brandnewTrain import train_gcn_cnn
import torch
import torch.nn as nn
from collections import Counter

# ì›ë³¸ main í•¨ìˆ˜ ë°±ì—…
original_main = train_gcn_cnn.main

def main_with_class_weights():
    # ì›ë³¸ parse_args í˜¸ì¶œ
    args = train_gcn_cnn.parse_args()
    train_gcn_cnn.set_seed(args.seed)

    from pathlib import Path
    data_dir = Path(args.data_dir)
    device = train_gcn_cnn.auto_device(args.device)

    if args.actions:
        selected_actions = [action.upper() for action in args.actions]
    else:
        selected_actions = train_gcn_cnn.SUPPORTED_ACTIONS

    action_to_label = {action: idx for idx, action in enumerate(sorted(set(selected_actions)))}
    label_to_action = {label: action for action, label in action_to_label.items()}

    # ìƒ˜í”Œ ìˆ˜ì§‘
    samples = train_gcn_cnn.collect_samples(
        data_dir=data_dir,
        action_to_label=action_to_label,
        frames_per_sample=args.frames_per_sample,
        persons=args.persons,
        actions=selected_actions,
    )

    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
    class_counts = Counter()
    for sample in samples:
        class_counts[sample.label] += 1

    print("\\n" + "=" * 60)
    print("âš–ï¸  í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°")
    print("=" * 60)

    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (inverse frequency)
    total_samples = len(samples)
    num_classes = len(action_to_label)

    class_weights = torch.zeros(num_classes)
    for label, count in class_counts.items():
        # weight = total / (num_classes * count)
        class_weights[label] = total_samples / (num_classes * count)

    # ì •ê·œí™” (ì„ íƒì )
    class_weights = class_weights / class_weights.sum() * num_classes

    print("\\ní´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ë° ê°€ì¤‘ì¹˜:")
    for label in sorted(class_counts.keys()):
        action = label_to_action[label]
        count = class_counts[label]
        weight = class_weights[label].item()
        print(f"  {action:10s} (label={label}): {count:4d}ê°œ â†’ ê°€ì¤‘ì¹˜ {weight:.3f}")

    print("=" * 60 + "\\n")

    # ì›ë³¸ ì½”ë“œ ì‹¤í–‰í•˜ë˜ criterionë§Œ êµì²´
    train_samples, val_samples = train_gcn_cnn.split_samples(samples, args.val_split, args.seed)

    print(f"â–¶ í•™ìŠµ ìƒ˜í”Œ: {len(train_samples)}ê°œ, ê²€ì¦ ìƒ˜í”Œ: {len(val_samples)}ê°œ")
    train_gcn_cnn.print_split_summary("TRAIN", train_samples)
    train_gcn_cnn.print_split_summary("VAL", val_samples)

    dataset_args = dict(frames_per_sample=args.frames_per_sample)
    train_dataset = train_gcn_cnn.PoseSequenceDataset(train_samples, **dataset_args)
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
    )

    val_loader = None
    if val_samples:
        val_dataset = train_gcn_cnn.PoseSequenceDataset(val_samples, **dataset_args)
        val_loader = torch.utils.data.DataLoader(
            val_dataset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=args.num_workers,
            pin_memory=True,
        )

    # ëª¨ë¸ ìƒì„±
    input_dim = 2
    adjacency = train_gcn_cnn.build_adjacency(train_gcn_cnn.USED_LANDMARK_INDICES)
    model = train_gcn_cnn.GCNTemporalModel(
        input_dim=input_dim,
        num_classes=len(action_to_label),
        adjacency=adjacency,
        gcn_hidden_dims=args.gcn_hidden_dims,
        temporal_channels=args.temporal_channels,
        dropout=args.dropout,
    )
    model.to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)

    # ğŸ”¥ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©í•œ ì†ì‹¤ í•¨ìˆ˜
    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))

    # í•™ìŠµ ë£¨í”„ (ì›ë³¸ê³¼ ë™ì¼)
    import math
    best_val_acc = -math.inf
    best_epoch = -1
    checkpoint_path = Path(args.save_dir) / args.save_name

    history = []
    for epoch in range(1, args.epochs + 1):
        train_result = train_gcn_cnn.train_one_epoch(
            model,
            train_loader,
            criterion,
            optimizer,
            device,
            grad_clip=args.grad_clip,
        )

        scheduler.step()

        if val_loader:
            val_result = train_gcn_cnn.evaluate(model, val_loader, criterion, device, label_to_action)
            val_loss = val_result.loss
            val_acc = val_result.accuracy

            print(f"[Epoch {epoch:3d}/{args.epochs}] Train Loss={train_result.loss:.4f} Acc={train_result.accuracy:.2%} | "
                  f"Val Loss={val_loss:.4f} Acc={val_acc:.2%}")

            if val_result.per_action:
                for action, (correct, total) in sorted(val_result.per_action.items()):
                    acc = correct / total if total > 0 else 0
                    print(f"  {action:10s}: {correct:3d}/{total:3d} ({acc:.1%})")

            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_epoch = epoch

                if not args.no_checkpoint:
                    train_gcn_cnn.save_checkpoint(
                        checkpoint_path,
                        model,
                        optimizer,
                        epoch,
                        best_val_acc,
                        args,
                        action_to_label,
                    )
                    print(f"  âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path}")
        else:
            print(f"[Epoch {epoch:3d}/{args.epochs}] Train Loss={train_result.loss:.4f} Acc={train_result.accuracy:.2%}")

    print(f"\\nğŸ‰ í•™ìŠµ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.2%} (Epoch {best_epoch})")
    if not args.no_checkpoint:
        print(f"âœ… ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {checkpoint_path}")

# ìˆ˜ì •ëœ main ì‹¤í–‰
main_with_class_weights()
""",
    "--",
    "--data_dir", "./app/brandnewTrain/pose_sequences",
    "--epochs", "150",
    "--save_name", "brandnew_balanced_v1.pt",
    "--batch_size", "32",
]

print(f"ì‹¤í–‰ ëª…ë ¹: python [class_weight_training_logic]\n")
result = subprocess.run(cmd)

if result.returncode == 0:
    print("\n" + "=" * 80)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("=" * 80)
    print("ëª¨ë¸ ì €ì¥: app/brandnewTrain/checkpoints/brandnew_balanced_v1.pt")
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  1. ëª¨ë¸ êµì²´:")
    print("     mv app/brandnewTrain/checkpoints/brandnew_model_v1.pt app/brandnewTrain/checkpoints/brandnew_model_v1_old.pt")
    print("     cp app/brandnewTrain/checkpoints/brandnew_balanced_v1.pt app/brandnewTrain/checkpoints/brandnew_model_v1.pt")
    print("  2. í…ŒìŠ¤íŠ¸:")
    print("     python test_brandnew_server.py --samples 3")
    print("=" * 80)
else:
    print("\nâŒ í•™ìŠµ ì‹¤íŒ¨!")
    sys.exit(1)
