# 흥부자 발표 대본 (수정본)

---

## 📌 핵심 차별점 3가지

1. **MCP (Model Context Protocol) 기반 명령 처리**
   - GPT가 직접 Tool을 선택하는 확장 가능한 아키텍처

2. **어떤 노래든 자동으로 게임용 데이터 생성**
   - Music 서버: 오디오 + 가사만 업로드하면 30초 내 분석 완료

3. **실시간 AI 모션 인식 + 동적 난이도 조정**
   - GCN+CNN 하이브리드 모델 + 1절 점수 기반 2절 레벨 자동 선택

---

## 1. 기획 배경 - 문제와 해결

### 1.1 문제 인식

**현대 사회 어르신들이 직면한 3가지 핵심 문제**

1. **디지털 소외**
   - 복잡한 UI/UX로 인한 기술 접근성 장벽
   - 작은 글씨, 터치 조작의 어려움

2. **신체 활동 부족**
   - 집에서 즐길 수 있는 운동 콘텐츠 부족
   - 기존 체조 프로그램의 낮은 흥미도

3. **응급 상황 대응 지연**
   - 혼자 계실 때 응급 상황 발생 시 신고 어려움
   - 스마트폰을 찾아 전화하기까지의 시간 소요

### 1.2 해결 방안

**"음성만으로 모든 것을 해결할 수 있다면?"**

→ **흥부자**: 어르신을 위한 **음성 인터페이스 기반** 엔터테인먼트 및 응급 관리 통합 시스템

---

## 2. 서비스 소개

### 2.1 핵심 기능

#### (1) 음성 명령 제어 - MCP 기반

**사용자 경험**
```
어르신: "트와이스 노래 틀어줘"
시스템: [음성 인식] → [Tool 선택] → [노래 재생] → "트와이스의 TT를 재생할게요"
```

**기술 구현 (MCP - Model Context Protocol)**
```
1. Whisper STT: 음성 → 텍스트
2. GPT에게 8가지 Tool 제공:
   - search_song, control_playback, handle_emergency
   - cancel_emergency, confirm_emergency, change_mode
   - start_game, start_game_with_song

3. GPT가 JSON으로 Tool 선택:
   {"tool_calls": [{"name": "search_song", "arguments": {"artist": "트와이스"}}]}

4. McpToolService가 해당 Tool 실행
5. TTS 음성 응답
```

**왜 MCP를 사용했나?**
- **확장성**: 새로운 Tool 추가가 쉬움 (GPT에게 Tool 설명만 추가)
- **유연성**: 복잡한 switch문 없이 GPT가 알아서 판단
- **유지보수성**: Intent 분류 로직을 GPT에게 위임

#### (2) 음악 체조 게임

**게임 플로우**
```
1. "게임 시작" 음성 명령
2. 옛날 노래 재생 + 안무 가이드 영상 표시
3. 카메라로 어르신 동작 촬영 (120ms 간격)
4. AI 실시간 판정 (Perfect / Good / Soso)
5. 1절 점수에 따라 2절 난이도 자동 조정
6. 게임 종료 후 동작별 점수 표시
```

**기술 구현**
- **WebSocket 실시간 통신**: 프레임 전송 및 피드백 수신
- **AI 모션 인식**: Mediapipe + GCN+CNN 모델
- **동적 난이도**: 1절 80점 이상 → Lv3, 60점 이상 → Lv2

#### (3) 응급 상황 자동 신고

**응급 플로우**
```
1. "도와주세요" → GPT가 handle_emergency Tool 선택
2. 진행 중인 활동 즉시 중단
3. "괜찮으세요?" TTS 재생
4. 60초 응답 없으면 자동 확정
5. 관리자에게 WebSocket 실시간 알림
```

#### (4) 건강 모니터링 관리자 페이지

**관리자 페이지 기능**
```
관리자가 각 어르신의 기기-사용자 카드를 클릭하면
→ 건강 모니터링 패널 확장 표시
```

**표시 정보 3가지**

1. **💪 건강 모니터링 요약**
   - 총 게임 수: 누적 게임 플레이 횟수
   - 평균 점수: 전체 게임 평균 점수
   - PERFECT 비율: 총 동작 중 Perfect(3점) 비율
   - 완료율: 게임 시작 대비 완료 비율

2. **🎯 동작별 수행도 (막대 그래프)**
   - **잘하는 동작**: CLAP, STRETCH 등 점수 높은 동작
   - **개선 필요 동작**: TILT, UNDERARM 등 점수 낮은 동작
   - 색상 코딩:
     - 녹색: 평균 점수 80점 이상 (잘함)
     - 주황: 평균 점수 60-80점 (보통)
     - 빨강: 평균 점수 60점 미만 (개선 필요)

3. **📈 활동 추이 (최근 7일 차트)**
   - 일별 게임 횟수 라인 차트
   - 추세 분석:
     - "최근 활동량이 증가하고 있습니다 📈"
     - "활동량이 감소 추세입니다. 관심이 필요합니다 📉"
     - "꾸준히 활동 중입니다 ✅"

**UI/UX 특징**
- 반응형 그리드 레이아웃 (모바일/태블릿/PC 대응)
- 애니메이션 & 호버 효과로 직관적 인터랙션
- 한눈에 파악 가능한 시각화 (차트, 그래프, 색상 코딩)

**활용 사례**
- 요양 시설: 어르신 건강 상태 모니터링
- 가족: 부모님 활동량 확인 및 건강 관리
- 운동 효과 분석: 어떤 동작이 어려운지 파악 → 맞춤 지도

---

## 3. 🎯 핵심 차별점 #1: Music 서버 - 어떤 노래든 자동 분석

### 3.1 기존 문제

**기존 음악 게임의 한계**
- 수작업 비트맵 제작: 며칠~몇 주 소요
- 곡 추가 비용이 높음
- 확장성 떨어짐

### 3.2 우리의 해결책

**오디오 파일(.mp3) + 가사 텍스트(.txt) 업로드 → 30초 내 자동 분석!**

#### API 엔드포인트
```python
POST /api/analyze
- audio: 오디오 파일
- lyrics: 가사 텍스트 (한 줄에 한 라인)
- title: 곡 제목

반환:
- beats_json: 비트 정보 (BPM, 비트 타임스탬프)
- lyrics_json: 가사 타이밍 정보
- duration: 곡 길이
```

#### 핵심 기술: Librosa + Scipy

**1) BPM 및 비트 검출**
```python
# HPSS (Harmonic-Percussive Source Separation)
y_h, y_p = librosa.effects.hpss(y)  # 타악기/화음 분리

# 비트 검출 (타악기 성분 사용)
tempo, beats = librosa.beat.beat_track(y=y_h, sr=44100, units='time')
bpm = 60.0 / np.median(np.diff(beats))
```

**2) 가사 타이밍 자동 추정 (핵심!)**
```python
# 보컬 엔벨로프 생성
b, a = butter_bandpass(200, 5000, sr)  # 200-5000Hz (보컬 주파수)
y_bp = filtfilt(b, a, y_h)             # 대역 필터링
rms = librosa.feature.rms(y=y_bp)      # RMS 에너지
env = lowpass_env(rms, cutoff_hz=5)    # 스무딩 (0.2초)

# 가사 경계 추정
cum_energy = np.cumsum(env)
targets = np.linspace(0, 1, len(lyrics_lines) + 1)

for target in targets:
    # 1. 목표 에너지 위치 찾기
    idx = np.searchsorted(cum_energy, target * cum_energy[-1])
    t0 = times[idx]

    # 2. 주변 2.5초 범위에서 Valley(에너지 낮은 지점) 찾기
    valleys = find_peaks(1.0 - env, prominence=0.02)
    nearest_valley = find_nearest_valley(t0, valleys, window=2.5)

    # 3. 비트에 스냅 (0.2초 이내 다음 비트로 조정)
    snapped_time = snap_to_next_beat(nearest_valley, beats, max_ahead=0.2)
    boundary_times.append(snapped_time)
```

**3) JSON 생성**
```python
beats_json = {
    "songId": 1,
    "bpm": 98.6,
    "beats": [
        {"i": 1, "bar": 1, "beat": 1, "t": 0.544},
        {"i": 2, "bar": 1, "beat": 2, "t": 1.154},
        ...
    ]
}

lyrics_json = {
    "songId": 1,
    "lines": [
        {
            "lineIndex": 1,
            "text": "하늘을 바라봐",
            "start": 15,  # 초
            "end": 18,
            "sBeat": 25,  # 시작 비트
            "eBeat": 30   # 종료 비트
        },
        ...
    ]
}
```

### 3.3 성과

| 항목 | 기존 방식 | 우리 시스템 |
|------|----------|-------------|
| **비트맵 제작 시간** | 며칠~몇 주 | **30초 이내** |
| **비용** | 전문가 고용 필요 | **거의 0원** |
| **확장성** | 낮음 (곡 추가 어려움) | **높음 (자동화)** |
| **적용 장르** | 제한적 | **모든 장르 가능** |

---

## 4. 🎯 핵심 차별점 #2: MCP 기반 명령 처리

### 4.1 기존 방식 vs MCP

**기존 방식 (Intent 분류 → Switch문)**
```java
// 문제점: 새로운 기능 추가 시 코드 수정 필요
Intent intent = classifier.classify(text);

switch (intent) {
    case SELECT_BY_ARTIST -> searchSong(artist);
    case MODE_EXERCISE -> startGame();
    case EMERGENCY -> handleEmergency();
    // ... 16개 case문
}
```

**MCP 방식 (GPT가 Tool 선택)**
```java
// 장점: Tool만 추가하면 GPT가 알아서 선택
1. Tool 목록을 GPT에게 제공
2. GPT가 JSON으로 Tool 선택
   {"tool_calls": [{"name": "search_song", "arguments": {...}}]}
3. McpToolService.executeTool(toolCall)
```

### 4.2 MCP 프롬프트 구조

```
당신은 노인을 위한 음성 인터페이스 AI입니다.
사용자의 음성 명령을 분석하여 적절한 Tool을 선택하세요.

[사용 가능한 Tools]
1. search_song: 가수명, 제목으로 노래 검색
2. start_game_with_song: 특정 노래로 게임 시작
3. handle_emergency: 응급 상황 처리
...

[사용자 명령]
"당돌한 여자로 체조하고 싶어"

[예상 응답]
{
  "tool_calls": [
    {"name": "start_game_with_song", "arguments": {"title": "당돌한 여자"}}
  ]
}
```

### 4.3 확장성

**새로운 기능 추가 시:**
1. Tool 클래스 작성 (5줄)
2. McpToolService에 Tool 등록 (1줄)
3. 프롬프트에 Tool 설명 추가 (3줄)
4. **끝! GPT가 알아서 판단**

---

## 5. 🎯 핵심 차별점 #3: AI 모션 인식 정확도

### 5.1 GCN + Temporal CNN 하이브리드 모델

**Mediapipe Pose (22개 관절 추출)**
```python
관절: 어깨, 팔꿈치, 손목, 엄지, 새끼손가락,
     골반, 무릎, 발목, 발꿈치, 발가락, 코, 입 (좌우 각각)

정규화:
1. 골반 중심으로 이동
2. 최대 거리로 스케일 조정
```

**모델 구조**
```python
Input: (8 frames, 22 joints, 2 coords) = (8, 22, 2)

↓ GCN Layer 1 (관절 간 공간 관계 학습)
  - 인접 행렬: 관절 간 연결 정보
  - 예: "손과 어깨의 거리" 학습

↓ GCN Layer 2

↓ 노드 평균 (그래프 임베딩) → (8, 128)

↓ Temporal CNN (시간 축 패턴 학습)
  - Conv1D(128 → 128 → 256)
  - 예: "손 박수 = 양손이 가까워졌다 멀어지는 반복"

↓ Global Average Pooling → (256,)

↓ Classifier
  - Linear(256 → 256) → ReLU → Dropout
  - Linear(256 → 5) → Softmax

Output: [CLAP, EXIT, STRETCH, TILT, UNDERARM] 확률
```

### 5.2 엄격한 채점 기준 (정확도 분석 후 조정)

**이전 문제점**
```
임계값 51%: 가만히 있어도 51% 확률 → 2점 (66.7점)
결과: 움직인 사람 75점 vs 정지한 사람 73점 (불공정)
```

**해결: 임계값 상향 조정**
```python
def _score_by_probability(probability: float) -> int:
    if probability >= 0.90: return 3  # Perfect (100점)
    if probability >= 0.75: return 2  # Good (66.7점)
    if probability >= 0.60: return 1  # Soso (33.3점)
    return 0  # Fail (0점)
```

**프레임 필터링 (유효 프레임만 사용)**
```python
valid_frames = [frame for frame in frames if np.any(frame)]
if len(valid_frames) < 5:
    raise ValueError("유효한 프레임 부족 (사람 감지 실패)")
```

---

## 6. 아키텍처 구성도

```
┌─────────────────────────────────────────┐
│   사용자 기기 (React SPA)                │
│   - HomePage, SongPage, GamePage        │
└──────────────┬──────────────────────────┘
               ↓ HTTPS
┌─────────────────────────────────────────┐
│   Nginx (리버스 프록시 + SSL)            │
│   /api/* → Spring, /motion/* → AI 서버  │
└──────────────┬──────────────────────────┘
               ↓
┌──────────────┴──────────────┬──────────────┬──────────────┐
│  Spring Boot (API 서버)      │ Motion AI     │ Music 서버   │
│                              │ (FastAPI)     │ (FastAPI)    │
│  - McpCommandServiceImpl    │ - Mediapipe   │ - Librosa    │
│  - McpToolService (8 Tools)  │ - GCN+CNN     │ - 자동 분석  │
│  - WebSocket (STOMP)         │ - PyTorch     │              │
│  - Emergency, Game, Song     │ - CUDA GPU    │              │
└──────────────┬──────────────┴──────────────┴──────────────┘
               ↓
┌──────────────┴──────────────────────────────────────────┐
│  데이터베이스                                              │
│  - MySQL: User, Device, GameResult, EmergencyReport     │
│  - MongoDB: Choreography, Beat, Lyrics, GameDetail      │
│  - Redis: GameState, ActivityState, ConversationContext │
│  - AWS S3: Audio, Video 파일                             │
└──────────────┬──────────────────────────────────────────┘
               ↓
┌──────────────┴──────────────────────────────────────────┐
│  외부 API                                                 │
│  - OpenAI Whisper (STT)                                  │
│  - OpenAI TTS (음성 합성)                                │
│  - GPT-5-nano (MCP Tool 선택)                            │
└───────────────────────────────────────────────────────────┘
```

---

## 7. 성능 최적화 - "처음에는 굉장히 느렸습니다"

### 7.1 초기 문제: 음성 컨트롤 응답이 너무 느렸다

**개선 전 전체 파이프라인 (STT → GPT → TTS)**
```
STT: 1,458ms + GPT: 6,802ms + TTS: 1,263ms = 9,523ms (약 9.5초)
```

**문제점**
- 사용자가 "트와이스 노래 틀어줘" 말한 후 **9.5초** 대기
- GPT 응답 실패율 **47.06%** (거의 절반이 실패!)
- TTS API 호출마다 **1.26초** 소요

### 7.2 개선 결과: 88.5% 속도 향상 + 98% 안정성

**개선 후 전체 파이프라인**
```
STT: 1,350ms + GPT: 7,910ms + TTS: 145ms = 9,405ms (약 9.4초)
```

#### (1) TTS 캐싱 - 88.5% 개선 🔥

**구현**
```java
// MongoDB에 텍스트 해시 기반 캐싱
String hash = SHA256(responseText);
if (cache.exists(hash)) {
    return cache.get(hash);  // 기존 MP3 재사용 (145ms)
}
String mp3 = openAiTtsApi.synthesize(responseText);  // API 호출 (1,263ms)
cache.save(hash, mp3);
```

**성과 (최근 8시간 기준)**
| 항목 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| **TTS 응답 시간** | 1,263ms | 145ms | **88.5% 단축** |
| **캐시 히트율** | 0% | **91.8%** (61번 요청 중 56번 히트) | - |
| **API 호출 절감** | - | **56번 절감** | **91.8% 감소** |
| **누적 시간 절감** | - | **62.6초** (8시간) | - |
| **캐시 항목 수** | 0개 | 105개 (평균 0.53회 재사용) | - |

**효과**
- 같은 응답 반복 시 **10배 이상 빠름** (1.26초 → 0.15초)
- 가장 인기 있는 응답: **46번 재사용** (극적인 비용 절감)
- 사용량 증가 시 캐시 효과는 더욱 증가

#### (2) GPT 안정성 향상 - 성공률 98.39% 달성 ✅

**구현**
- GPT 응답 파싱 실패 시 재시도 로직 추가
- 타임아웃 처리 강화
- 에러 핸들링 개선

**성과**
| 항목 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| **성공률** | 52.94% | **98.39%** | **거의 2배 향상** |
| **실패율** | 47.06% | 1.61% | **대폭 감소** |
| **평균 응답 시간** | 6,802ms | 7,910ms | 약간 증가 (재시도 로직) |

**트레이드오프**
- 속도보다 **안정성 우선**: 재시도 로직으로 약간 느려졌지만 성공률 2배
- 사용자가 실패 경험하는 확률: **47% → 1.6%**

#### (3) STT 최적화 - 7.4% 개선

| 항목 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| **STT 응답 시간** | 1,458ms | 1,350ms | **7.4% 단축** (108ms) |

#### (4) CUDA GPU 가속 (Motion AI)

- CPU 추론: 150ms
- GPU 추론: 45ms (3.3배 빠름)
- 총 모션 인식 응답: 500ms 이하

### 7.3 최종 성능 비교

**전체 음성 처리 파이프라인 (STT → GPT → TTS)**

| 구분 | 개선 전 | 개선 후 |
|------|---------|---------|
| STT | 1,458ms | 1,350ms (-7.4%) |
| GPT | 6,802ms (성공률 52.94%) | 7,910ms (성공률 **98.39%**) |
| TTS | 1,263ms | **145ms (-88.5%)** |
| **총합** | **9,523ms** | **9,405ms** |

### 7.4 핵심 성과

**"TTS 캐싱으로 API 호출 92% 절감, GPT 안정성 2배 향상"**

1. **똑똑한 캐싱 전략**
   - 같은 응답은 재생성하지 않음
   - 105개 문장 캐싱으로 92% 히트율 달성
   - 62초 절감 (최근 8시간 기준)
   - 사용량 증가 시 캐시 효과는 더욱 증가

2. **안정성 최우선**
   - GPT 성공률 98% 달성
   - 사용자가 실패 경험하는 확률 1.6%로 감소

3. **확장 가능성**
   - 캐시 히트율이 높아질수록 비용 절감 효과 누적
   - 월간 예상 API 호출 절감: 수천 건

---

## 8. 차별화 포인트

### 8.1 기술적 차별화

1. **MCP 기반 확장 가능한 아키텍처**
   - Tool 추가만으로 새로운 기능 확장
   - GPT가 자동으로 Tool 선택

2. **자동 음악 분석 시스템**
   - 어떤 노래든 30초 내 게임용 데이터 생성
   - 수작업 비트맵 제작 불필요

3. **실시간 AI 모션 인식 + 동적 난이도**
   - GCN+CNN 하이브리드 모델
   - 1절 점수 기반 2절 레벨 자동 조정

### 8.2 UX 차별화

1. **음성만으로 모든 제어**
   - 복잡한 버튼/메뉴 없음
   - 5초 녹음 → 자동 처리

2. **자동 화면 전환**
   - GPT가 선택한 Tool에 따라 화면 자동 전환
   - 사용자는 음성 명령만 하면 됨

3. **건강 모니터링 & 데이터 시각화**
   - 관리자 페이지에서 어르신별 건강 상태 한눈에 파악
   - 동작별 수행도 분석 → 맞춤 지도 가능
   - 활동 추이 분석 → 건강 상태 변화 모니터링
   - 요양 시설/가족이 쉽게 관리할 수 있는 직관적 UI

---

## 9. 향후 개선 방향

1. **추천 시스템**: 청취 이력 기반 노래 자동 추천
2. **모델 경량화**: ONNX 변환으로 추론 속도 향상
3. **B2B 확장**: 요양원/노인정 대상 판매

---

## 10. 마무리

### 핵심 메시지

> **"흥부자는 단순한 음악 재생 앱이 아닙니다.
> 어르신의 일상을 바꾸는 AI 기반 헬스케어 플랫폼입니다."**

### 기술적 성과
- ✅ MCP로 확장 가능한 아키텍처 구현
- ✅ 자동 음악 분석으로 곡 추가 비용 제로화
- ✅ 실시간 AI 모션 인식 + 동적 난이도

### 우리 팀의 강점
1. **풀스택 역량**: React + Spring + FastAPI + AI 모델 직접 구현
2. **실전 경험**: MCP 아키텍처, 자동 음악 분석, 엄격한 채점 기준 조정
3. **문제 해결 능력**: 51% → 90%/75%/60% 임계값 조정으로 공정성 확보

### 감사합니다!
